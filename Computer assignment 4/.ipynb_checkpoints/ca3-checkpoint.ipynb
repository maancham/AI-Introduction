{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"font-size: 35px; text-align: center;\">AI CA3</h2>\n",
    "<h2 style = \"font-size: 35px; text-align: center;\">Data processing and bayesian networks</h2>\n",
    "<h2 style = \"font-size: 32px; text-align: center; color: #666\">Houmch 810196443</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import math\n",
    "import hazm as hz\n",
    "from hazm import stopwords_list\n",
    "from hazm import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_name = \"comment_train.csv\"\n",
    "test_file_name = \"comment_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"text-align: center\">Prelude</h1>\n",
    "<br>\n",
    "<h2>Definition of project:</h2>\n",
    "<p style = \"font-size: 14px\">Text classification is useful in lots of aspects, for instance: spam email recognition, automatic book classification and ...\n",
    "<br>    \n",
    "    The goal of this project is to classify texts based on <mark>comments</mark> and <mark>titles</mark>. We have two main categories: <b>recommended and not_recommended </b> and data stored at <mark>comment_train.csv & comment_test.csv</mark>.\n",
    "<br>\n",
    "First of all we train system with train dataset with a strategy called <b>bag of words</b>, then for evaulation we use test dataset.Lastly we measure accuracy, recall, and precision for each one of the four processing methods.\n",
    "<br></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<h1 style= \"text-align: center\">Prerequisites </h1>\n",
    "<br>\n",
    "<h3>Preprocessing data: </h3>\n",
    "<p><mark>preprocess()</mark>: Every context in training data should be preprocessed in order to extract main words and to calculate probability of words per categories. preprocessing steps are shown below:</p>\n",
    "<p style=\"text-indent :2em;\">1. <mark>Normalize()</mark>: The normalization process can improve text matching. For example, there are several ways that the term \"modem router\" can be expressed, such as modem and router, modem & router, modem/router, and modem-router. By normalizing these words to the common form, it makes it easier to supply the right information to a shopper. By transforming the words to a standard format, other operations are able to work with the data and will not have to deal with issues that might compromise the process.</p>\n",
    "\n",
    "<p style=\"text-indent :2em;\">2. <mark>lemmatize()</mark>: This function uses <b>hazm library</b> to lemmatizes words.</p>\n",
    "<p style=\"text-indent :2em;\">3. <mark>remove_stopwords()</mark>: This function uses <b>hazm library</b> and tokenizer to remove <b>stopWords and punctuations</b>.</p>\n",
    "\n",
    "## Question 1:  what is stemming and lemmatization?\n",
    "<p>The main difference between lemmatization and stemming is the way they work and therefore the result they each of them returns</p>\n",
    "<p><b>Stemming</b> algorithms work by cutting off the end or the beginning of the word, taking into account a list of common prefixes and suffixes that can be found in an inflected word while <b>lemmatization</b>, on the other hand, takes into consideration the morphological analysis of the words. To do so, it is necessary to have detailed dictionaries which the algorithm can look through to link the form back to its lemma.</p>\n",
    "<p>In our project lemmatization works a bit better with better accuracy.</p>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords_list()\n",
    "\n",
    "def normalize():\n",
    "    normalizer = hz.Normalizer()\n",
    "    train_df['title'] = train_df['title'].apply(lambda x: normalizer.normalize(x))\n",
    "    train_df['comment'] = train_df['comment'].apply(lambda x: normalizer.normalize(x))\n",
    "    test_df['title'] = test_df['title'].apply(lambda x: normalizer.normalize(x))\n",
    "    test_df['comment'] = test_df['comment'].apply(lambda x: normalizer.normalize(x))\n",
    "\n",
    "def lemmatize():\n",
    "    lemmatizer = hz.Lemmatizer()\n",
    "    train_df['title'] = train_df['title'].apply(lambda x: lemmatizer.lemmatize(x))\n",
    "    train_df['comment'] = train_df['comment'].apply(lambda x: lemmatizer.lemmatize(x))\n",
    "    test_df['title'] = test_df['title'].apply(lambda x: lemmatizer.lemmatize(x))\n",
    "    test_df['comment'] = test_df['comment'].apply(lambda x: lemmatizer.lemmatize(x))\n",
    "\n",
    "# def stemmer():\n",
    "#     stemmer = hz.Stemmer()\n",
    "#     train_df['title'] = train_df['title'].apply(lambda x: stemmer.stem(x))\n",
    "#     train_df['comment'] = train_df['comment'].apply(lambda x: stemmer.stem(x))\n",
    "#     test_df['title'] = test_df['title'].apply(lambda x: stemmer.stem(x))\n",
    "#     test_df['comment'] = test_df['comment'].apply(lambda x: stemmer.stem(x))\n",
    "    \n",
    "def trim_cell(input_cell):\n",
    "    cell_array = word_tokenize(input_cell)\n",
    "    filtered_sentence = [] \n",
    "    for i in cell_array:\n",
    "        if i not in stop_words:\n",
    "             filtered_sentence.append(i)\n",
    "    return filtered_sentence\n",
    "\n",
    "def remove_stopwords():\n",
    "    train_df['title'] = train_df['title'].apply(lambda x: trim_cell(str(x)))\n",
    "    train_df['comment'] = train_df['comment'].apply(lambda x: trim_cell(str(x)))\n",
    "    test_df['title'] = test_df['title'].apply(lambda x: trim_cell(str(x)))\n",
    "    test_df['comment'] = test_df['comment'].apply(lambda x: trim_cell(str(x)))\n",
    "    \n",
    "\n",
    "def join_columns():\n",
    "    train_df[\"joined\"] = train_df[\"title\"] + train_df[\"comment\"]\n",
    "    test_df[\"joined\"] = test_df[\"title\"] + test_df[\"comment\"]\n",
    " \n",
    "\n",
    "    \n",
    "def preprocess():\n",
    "    normalize()\n",
    "#     stemmer()\n",
    "    lemmatize()\n",
    "    remove_stopwords()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:  what is bag of words?\n",
    "\n",
    "<p>Bag of words is a model which is insensitive to word orders. it uses bayesian networks and naive bayes to calculate probabilites. In our model we have 4 types of probabilites: </p>\n",
    "<p style=\"text-indent :2em;\">1. <mark>Posterier: p(c|x)</mark>: If we have the <b>x</b> as a word in our text, what is the probability of <b>c</b> category for this text.</p>\n",
    "<p style=\"text-indent :2em;\">2. <mark>Prior: p(c)</mark>: the probability of <b>c</b> as category (calculated based on training data). </p>\n",
    "<p style=\"text-indent :2em;\">3. <mark>Likelihood: p(x|c)</mark>: If we know that <b>c</b> is category of current text, what is the probability that this text contains word <b>x</b>.</p>\n",
    "<p style=\"text-indent :2em;\">4. <mark>Evidence: p(x)</mark>: the probability of exitance of <b>x</b> as a word in text. We devide the number of current word to total words to calculate p(x) for every x.</p>\n",
    "<p><b>NOTE 1</b>: At the end we use <b>p(c|X = {x1,x2,x3,...}) = p(x1|c)*p(x2|c)* ..... * p(c)</b> to evaluate.</p>\n",
    "\n",
    "### Implementation Explanation:\n",
    "<p> First off I divided train_df into to parts based on their \"recommend\" column. After that on each new dataframe these steps are carried out sequnetially:\n",
    "<p style=\"text-indent :2em;\">1. <mark>List definition</mark>: Go through all the rows of the dataframe and append each one of the encountered words to a list.</p>    \n",
    "<p style=\"text-indent :2em;\">2. <mark>Dict definition</mark>: Make a dictionary based on that list. This dict is made up of a key denoted by \"word\" and a value equal to the number of occurrences of the said word divided by the total number of words.</p> <p style=\"text-indent :2em;\">3. <mark>Dict Normalization</mark>: In order to make values a bit more comprehensible, each value has been replaced by it's corresponding logarithm (base 10). By using this method we can use addition instead of multiplication when calculating the p(c|X = {x1,x2,x3,...}).</p>\n",
    "<p style=\"text-indent :2em;\">4. <mark>Smoothin value definition</mark>: Smoothing method has been fully explained below but in brief, this variable is defined for each one of the dataframes and it contains smoothing value. It will be used in cases where a word has not been encountered before so that the naive bayes model would not crash!</p>\n",
    "<p style=\"text-indent :2em;\">5. <mark>P(c) calculation</mark>: Last but not least, this probability is the lenght of each one of the dataframes divided by the lenght of the original dataframe(train_df).</p> \n",
    "</p>\n",
    "\n",
    "## Question 3&4:  Additive smoothing\n",
    "<p>Let's say you've trained your Naive Bayes Classifier on 2 classes, \"Ham\" and \"Spam\" (i.e. it classifies emails). For the sake of simplicity, we'll assume prior probabilities to be 50/50.\n",
    "Now let's say you have an email (w1,w2,...,wn) which your classifier rates very highly as \"Ham\", say: <mark> P(Ham|w1,w2,...wn)=0.90 and P(Spam|w1,w2,..wn)=0.10 </mark>.Now let's say you have another email (w1,w2,...,wn,wn+1) which is exactly the same as the above email except that there's one word in it that isn't included in the vocabulary. Therefore, since this word's count is 0. So now we have: <mark> P(Ham|wn+1)=P(Spam|wn+1)=0 </mark> and <mark> P(Spam|w1,w2,..wn,wn+1)=P(Spam|w1,w2,...wn)∗P(Spam|wn+1)=0 </mark>. Despite the 1st email being strongly classified in one class, this 2nd email may be classified differently because of that last word having a probability of zero.\n",
    "\n",
    "<b>Laplace smoothing</b> solves this by giving the last word a small non-zero probability for both classes, so that the posterior probabilities don't suddenly drop to zero.\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "### Method of calculating p(x|c):\n",
    "#### This method is used to consider the additive smoothing value in probabilities.\n",
    "<h5 style = \"font-size: 20px; text-align: center;\"><mark> div_value </mark> = Unique words in Category c + occurance of Category c + 1</h5>\n",
    "<h5 style = \"font-size: 20px; text-align: center;\"> <mark> P(x|c) </mark> = Number of occurances + 1 / div_value</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predictor():\n",
    "    good_train_df = train_df[train_df.recommend == \"recommended\"]\n",
    "    bad_train_df = train_df[train_df.recommend == \"not_recommended\"]\n",
    "    method_index = 1\n",
    "    good_train_df\n",
    "\n",
    "    words_in_goods = []\n",
    "    words_in_bads = []\n",
    "    for i in range(len(good_train_df.index)):\n",
    "        lst = good_train_df.iloc[i]['joined']\n",
    "        for j in lst:\n",
    "            words_in_goods.append(j)\n",
    "\n",
    "    for i in range(len(bad_train_df.index)):\n",
    "        lst = bad_train_df.iloc[i]['joined']\n",
    "        for j in lst:\n",
    "            words_in_bads.append(j)\n",
    "\n",
    "\n",
    "\n",
    "    good_words_dict = {}\n",
    "    bad_words_dict = {}\n",
    "    g_words_size = len(words_in_goods)\n",
    "    b_words_size = len(words_in_bads)\n",
    "    g_vocab_size = len(Counter(words_in_goods).keys())\n",
    "    b_vocab_size = len(Counter(words_in_bads).keys())\n",
    "    count_g = len(good_train_df.index)\n",
    "    count_b = len(bad_train_df.index)\n",
    "    \n",
    "    if (method_index == 1):\n",
    "        for word in words_in_goods:\n",
    "            if (word not in good_words_dict):\n",
    "                good_words_dict[word] = 1/g_words_size\n",
    "            else:\n",
    "                good_words_dict[word] += 1/g_words_size\n",
    "\n",
    "        for word in words_in_bads:\n",
    "            if (word not in bad_words_dict):\n",
    "                bad_words_dict[word] = 1/b_words_size\n",
    "            else:\n",
    "                bad_words_dict[word] += 1/b_words_size\n",
    "                \n",
    "    else:\n",
    "        for word in words_in_goods:\n",
    "            if (word not in good_words_dict):\n",
    "                good_words_dict[word] = 1/(count_g + g_vocab_size + 1)\n",
    "            else:\n",
    "                good_words_dict[word] += 1/(count_g + g_vocab_size + 1)\n",
    "\n",
    "        for word in words_in_bads:\n",
    "            if (word not in bad_words_dict):\n",
    "                bad_words_dict[word] = 1/(count_b + b_vocab_size + 1)\n",
    "            else:\n",
    "                bad_words_dict[word] += 1/(count_b + b_vocab_size + 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for word in good_words_dict:\n",
    "        good_words_dict[word] = math.log(good_words_dict[word], 10)\n",
    "\n",
    "    for word in bad_words_dict:\n",
    "        bad_words_dict[word] = math.log(bad_words_dict[word], 10)    \n",
    "\n",
    "    if (method_index == 1):\n",
    "        gmoothing_value = int(good_words_dict[min(good_words_dict, key=good_words_dict.get)]) - 1\n",
    "        bsmoothin_value = int(bad_words_dict[min(bad_words_dict, key=bad_words_dict.get)]) - 1\n",
    "    else:\n",
    "        gmoothing_value = math.log(1/(count_g + g_vocab_size + 1), 10)\n",
    "        bsmoothin_value = math.log(1/(count_b + b_vocab_size + 1), 10)\n",
    "\n",
    "\n",
    "    good_p_c = math.log(len(good_train_df.index) / len(train_df.index), 10)\n",
    "    bad_p_c = math.log(len(bad_train_df.index) / len(train_df.index), 10)\n",
    "    \n",
    "    return (good_words_dict, good_p_c, bad_words_dict, bad_p_c, gmoothing_value, bsmoothin_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5:  Precision or Recall?\n",
    "<p> <b>Precision</b> means the percentage of your results which are relevant. On the other hand, <b>recall</b> refers to the percentage of total relevant results correctly classified by your algorithm </p>\n",
    "<p> Imagine a retail app, wherein there is a limited space on each webpage, and extremely limited attention span of the customer. Therefore, if the customer is shown a lot of irrelevant results and very few relevant results (in order to achieve a high recall), the customer will not keep browsing each and every product forever and will eventually leave the app. </p>\n",
    "<p> <b>Better Examples</b>: </p> \n",
    "<p style=\"text-indent :2em;\">1. <mark>Recall is High.</mark> Choose a scenario where we will consider all encountered comments to <mark> recommended </mark>. Since recall is correct detected recommended / total recommended then recall is 100% but our model is definately poor. </p>\n",
    "<p style=\"text-indent :2em;\">2. <mark>Precision is Hight</mark> Choose a scenario where we will consider only one test comment to be recommended. Since precision is calculated using correct detected recommended / all detected recommended and both values are 1 then our precision will be 100% but our model is definately poor.</p>\n",
    "\n",
    "## Question 6:  F1?\n",
    "<p> The F1 score is the <mark>harmonic mean</mark> of precision and recall taking both metrics into account. We use the harmonic mean instead of a simple average because it punishes extreme values. A classifier with a precision of 1.0 and a recall of 0 has a simple average of 0.5 but an F1 score of 0. The F1 score gives equal weight to both measures. <b> If we want to create a balanced classification model with the optimal balance of recall and precision, then we try to maximize the F1 score. </b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predictor(use_smoothing, good_words_dict, good_p_c, bad_words_dict, bad_p_c, gmoothing_value, bsmoothin_value):\n",
    "    answers = test_df['recommend'].tolist()\n",
    "    predictions = []\n",
    "    for m in range(800):\n",
    "        gprob = 0\n",
    "        gflag = False\n",
    "        bflag = False\n",
    "        bprob = 0\n",
    "        for i in test_df.iloc[m]['joined']:\n",
    "            if (i in good_words_dict):\n",
    "                gprob += good_words_dict[i]\n",
    "            elif (use_smoothing):\n",
    "                gprob += gmoothing_value\n",
    "            else:\n",
    "                gflag = True\n",
    "            \n",
    "            if (i in bad_words_dict):\n",
    "                bprob += bad_words_dict[i]\n",
    "            elif (use_smoothing):\n",
    "                bprob += bsmoothin_value\n",
    "            else:\n",
    "                bflag = True\n",
    "        \n",
    "        if (gflag):\n",
    "            gprob = 0\n",
    "        else:\n",
    "            gprob += good_p_c\n",
    "            gprob = 10**gprob\n",
    "        \n",
    "        if (bflag):\n",
    "            bprob = 0\n",
    "        else:\n",
    "            bprob += bad_p_c\n",
    "            bprob = 10**bprob\n",
    "        \n",
    "        if (gprob > bprob):\n",
    "            predictions.append('recommended')\n",
    "        elif (gprob < bprob):\n",
    "            predictions.append('not_recommended')\n",
    "        else:\n",
    "            choice = np.random.randint(2)\n",
    "            if (choice == 0):\n",
    "                predictions.append('recommended')\n",
    "            else:\n",
    "                predictions.append('not_recommended')\n",
    "    \n",
    "    wrong_shots_idx = [] \n",
    "    head_shots = 0\n",
    "    correct_detected_recomm = 0\n",
    "    all_detected_recomm = predictions.count('recommended')\n",
    "    total_recomm = answers.count('recommended')\n",
    "    for i in range(len(answers)):\n",
    "        if (answers[i] == predictions[i]):\n",
    "            if (answers[i] == 'recommended'):\n",
    "                correct_detected_recomm += 1\n",
    "            head_shots += 1\n",
    "        else:\n",
    "             wrong_shots_idx.append(i)\n",
    "\n",
    "    accuracy = head_shots / len(answers)\n",
    "    precision = correct_detected_recomm / all_detected_recomm\n",
    "    recall = correct_detected_recomm / total_recomm\n",
    "    f1 = 2*((precision * recall) / (precision + recall))\n",
    "    return (accuracy , precision, recall, f1, wrong_shots_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>91.38</td>\n",
       "      <td>92.11</td>\n",
       "      <td>90.50</td>\n",
       "      <td>91.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>63.75</td>\n",
       "      <td>64.86</td>\n",
       "      <td>60.00</td>\n",
       "      <td>62.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>85.88</td>\n",
       "      <td>85.79</td>\n",
       "      <td>86.00</td>\n",
       "      <td>85.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>64.38</td>\n",
       "      <td>65.67</td>\n",
       "      <td>60.25</td>\n",
       "      <td>62.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision  Recall     F1\n",
       "a     91.38      92.11   90.50  91.30\n",
       "b     63.75      64.86   60.00  62.34\n",
       "c     85.88      85.79   86.00  85.89\n",
       "d     64.38      65.67   60.25  62.84"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pretty_list(inp):\n",
    "    a = [100*x for x in inp]\n",
    "    return [round(num, 2) for num in a]\n",
    "\n",
    "\n",
    "report_df = pd.DataFrame(columns = ['Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "report_df['Accuracy'] = [0, 0, 0, 0]\n",
    "report_df['Precision'] = [0, 0, 0, 0]\n",
    "report_df['Recall'] = [0, 0, 0, 0]\n",
    "report_df['F1'] = [0, 0, 0, 0]\n",
    "report_df.index = ['a', 'b' , 'c', 'd']\n",
    "wrong_shots_idx = []\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    train_df = pd.read_csv(train_file_name)\n",
    "    test_df = pd.read_csv(test_file_name)\n",
    "    if (i == 0):\n",
    "        preprocess()\n",
    "        join_columns()\n",
    "        good_words_dict, good_p_c, bad_words_dict, bad_p_c, gmoothing_value, bsmoothin_value = train_predictor()\n",
    "        out = test_predictor(True, good_words_dict, good_p_c, bad_words_dict, \n",
    "                             bad_p_c, gmoothing_value, bsmoothin_value)\n",
    "        wrong_shots_idx = out[4]\n",
    "        out = out[0:4]\n",
    "        report_df.loc['a'] = pretty_list(out)\n",
    "        \n",
    "    elif (i == 1):\n",
    "        join_columns()\n",
    "        good_words_dict, good_p_c, bad_words_dict, bad_p_c, gmoothing_value, bsmoothin_value = train_predictor()\n",
    "        out = test_predictor(True, good_words_dict, good_p_c, bad_words_dict, \n",
    "                             bad_p_c, gmoothing_value, bsmoothin_value)\n",
    "        out = out[0:4]\n",
    "        report_df.loc['b'] = pretty_list(out)\n",
    "        \n",
    "    elif (i == 2):\n",
    "        preprocess()\n",
    "        join_columns()\n",
    "        good_words_dict, good_p_c, bad_words_dict, bad_p_c, gmoothing_value, bsmoothin_value = train_predictor()\n",
    "        out = test_predictor(False, good_words_dict, good_p_c, bad_words_dict, \n",
    "                             bad_p_c, gmoothing_value, bsmoothin_value)\n",
    "        out = out[0:4]\n",
    "        report_df.loc['c'] = pretty_list(out)\n",
    "    \n",
    "    elif (i == 3):\n",
    "        join_columns()\n",
    "        good_words_dict, good_p_c, bad_words_dict, bad_p_c, gmoothing_value, bsmoothin_value = train_predictor()\n",
    "        out = test_predictor(False, good_words_dict, good_p_c, bad_words_dict, \n",
    "                             bad_p_c, gmoothing_value, bsmoothin_value)\n",
    "        out = out[0:4]\n",
    "        report_df.loc['d'] = pretty_list(out)\n",
    "\n",
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: \n",
    "<p> When we are using both preprocess and additive smoothing, values are above 90 percent as presented above. The reason is that we are doing both essential parts of the bag of words model, first one being the cleaning of data and second one considering a small amount of probability for non-encountered words in training. One reason that the results are not in the hight 90's is that by using the bag of words method we are ignoring the realtion between words and structure of sentences within comments. </p>\n",
    "<p> In the second one we are no using any sort of preprocess and we are only using additive smoothing. As we can see, results are significantly lower. The reason is by ignoring the preprocess level there are words which must be eliminated in order make a better predictor. <b>Why do we need to remove stop words?</b> That is because stop words occur in abundance, hence providing little to no unique information that can be used for classification or clustering. Also no normalization is being done on the dataset.However, the result are better that random guess (50 precent) since we are using a method after all! </p>\n",
    "\n",
    "<p> The third method is better than the second since it uses preprocessing. We have explained why to use stop words removal above. Now, <b> Why do we need to normalize?</b> Basically, normalization is the process of efficiently organising data in a database. There are two main objectives of the normalization process: eliminate redundant data (storing the same data in more than one table) and ensure data dependencies make sense (only storing related data in a table). By ignoring the additive smoothing we will face problems when we encounter a new word in test dataset. But these ocuurances are not too much to present big obsticles. Also, a random method has been applied in those situations and as a result, there's a 50 precent chance (ammortized) that our prediction will be correct. </p>\n",
    "\n",
    "<p> Last but not least, we will have near random results when we igonre all mentioned methods in out prediction. No normalization and no additive smoothing will result in a dataset where there is <mark> resundant data </mark> and also luck will decide the fate in cases where we encounter a new word in test dataset. However, results are a bit better than absolute luck since at least a model (weak one!) is being applied on the dataset </p>\n",
    "\n",
    "## Question 9: \n",
    "<p> A better thing we could have done is to consider the linguistic features of comments. In the bag of words method, we are totaly ignoring how words are combined together into a sentence and we're just focusing on occurances of various words in each category. Also, I think it would be better to use a specific way removing stop words. when a comment is full of words associated with happiness and joy it is more likely to be under recommended category than not_recommended. (Calculating this probability is a project for itself!). </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment title:  دستگاه خیلی ضعیف\n",
      "comment body:  من این فیس براس چند روز یپش به دستم رسید و الان بعد از چند روز استفاده از همه سری هاش دارم نظرم رو مینویسم\r\n",
      "اول تشکر کنم بابت ارسال و بسته بندیه خوب دیجیکالا \r\n",
      "و اینکه این فیس براش رو من توی تخفیف خریدم. اول اینکه دستگاه به شدت ضعیفه با اینکه من 4تا باطری خوب هم انداختم روش ولی بازم خیلی ضعیفه در حدی که زود خاموش میشه! برس صورتش به نظر من باید لطیف تر باشه و برعکس برس بدنش باید یکم زبر تر باشه که بتونه لایه برداری انجام بده ولی برای شستشو معمولی بدن بد نیست ولی خب انقد ضعیفه که نمیشه باهاش شست. من تصمیم دارم بازش کنم و خودم قوی ترش کنم امیدوارم اون موقع بهتر بشه. در کل بنظر من بد حد یه فیس براش دستیه ولی آدم پولش رو جمع کنه و یه بهترش رو بخره خیلی بهتره چون این حتی سری هاشم گیر نمیاد و وقتی سری ها خراب بشن دیگه قابل استفاده نیست..\n",
      "expected result:  not_recommended\n",
      "-------------------------------------------------\n",
      "comment title:  نقد پس از خرید\n",
      "comment body:  سلام ، راحت شدم از کابل شارژ ، توصیه میشود به شدت . ارزان گوشی خود را به شارژ وایرلس مجهز کنید .\n",
      "expected result:  recommended\n",
      "-------------------------------------------------\n",
      "comment title:  گزینه خوبیه\n",
      "comment body:  سلام ، گزینه خوبیه من یه mg2540  خریده بودم یعنی رسما منو روانی کرد ..\r\n",
      "کارتریجش کنتور داشت بعد ۳۰۰ برگ نمیزد دیگه ! \r\n",
      "این که به دستم رسید حس  خلاص شدن از دست شارژ کارتریج و تعویض کارتریج کاملا حس کردم .\r\n",
      "پرینتر خوبیه   کیفیت چاپش بسیاااااار فوق العاده هستش   کاغذ با کیفیت بخرید و پرینت بگیرید  قطعا متوجه منظورم میشید ! (کاغد معمولی A4 هم باید با کیفیت بخرید)\r\n",
      "۳..۴ تا عکس اتلیه ای چاپ کردم چسبوندم رو تخته شاسی  با عکس اتلیه اصلی مو نزد !\r\n",
      "خلاصه اینو پیشنهاد میکنم ولی بازم یه جمع بندی کنید\r\n",
      "اگر مشکل مالی ندارید   g3400 یا g3410 بخرید  که وایرلس هم داره \r\n",
      "ولی برا من بودن و نبود وایفای فرق نمیکنه  شمارو نمیدونم \r\n",
      "یه نکته حساس و مهم ؛ رنگ مشکی این پرینتر پیگمنته و از ذرات جامد تشکیل شده   هر شب سعی کنید یه پرینت بگیرید ازش  حداکثر  ۲ روز یبار   که جوهر رسوب نکنه  و هد رو خراب کنه !\n",
      "expected result:  recommended\n",
      "-------------------------------------------------\n",
      "comment title:  خیالم راحت شد\n",
      "comment body:  فندک قبلیم مدام فیوز میسوزوند و یک بار شارژر موبایل هم سوزوند ولی با این هیچ مشکلی بوجود نیومده تا الان. کیفیتش خیلی خوبه و لامپ هم داره\n",
      "expected result:  recommended\n",
      "-------------------------------------------------\n",
      "comment title:  کت مناسب\n",
      "comment body:  برای پسرم تهیه کردم خیلی قشنگه دوخت عالی داره بعده شستشو تغییر نکرد در ضمن خیلی لطیفه ،پیشنهاد میکنم بخرید\n",
      "expected result:  recommended\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "five_wrongs = wrong_shots_idx[0:5]\n",
    "for i in range(5):\n",
    "    element = test_df.iloc[five_wrongs[i]]\n",
    "    print(\"comment title: \", element['title'])\n",
    "    print(\"comment body: \", element['comment'])\n",
    "    print(\"expected result: \", element['recommend'])\n",
    "    print('-------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
